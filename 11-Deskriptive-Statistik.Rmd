---
output: html_document
editor_options: 
  chunk_output_type: console
---
# (PART) Statistik {-}

# Deskriptive Statistik

In diesem Abschnitt widmen wir uns univariaten und bivariaten *deskriptiven Statistiken*, vom Mittelwert und Standardabweichung über $\chi^2$, *Somers' d* und Korrelationskoeffizienten.  
Wir halten uns (so grob) an die Struktur aus QM1 und QM2, das heißt: Wir kümmern uns beispielsweise zuerst um $\chi^2$ als deskriptive Statistik um dann auf *Cramer's V* zu sprechen zu kommen, und widmen uns erst im folgenden Kapitel dem $\chi^2$-Test als inferenzstatistisches Werkzeug.

## Univariate Statistiken

*Univariat* ist *fancy sprech* für "nur eine Variable", das heißt es geht erstmal noch nicht um Zusammenhänge irgendeiner Art, sondern primär darum wie ein Merkmal **verteilt** ist.  
Die dazugehörigen Kennwerte und Formeln sind sozusagen das kleine 1x1 der Statistik, dementsprechend sind sie auch in R schnell und einfach erreichbar.  
Als Beispieldatensatz nehmen wir wieder den *Game of Thrones Deaths*-Datensatz und den `qmsurvey`-Datensatz, beide aus dem Kapitel [Datenimport]:

```{r ch11_Daten_einlesen, message=FALSE, warning=FALSE}
qmsurvey  <- readRDS("data/qm-survey-2017-R.rds")
gotdeaths <- readr::read_csv("data/got_deaths.csv")
```

### Mittelwert, Median, Modus

Mittelwert und Median sind einfach: 

```{r ch_11_mean_median}
mean(qmsurvey$zufrieden)
median(qmsurvey$zufrieden)
```

Die Funktionen `mean` und `median` sind da wenig überraschend.  
Aber was machen wir mit dem Modus? In R an sich gibt es keine `modus`-Funktion, deswegen haben wir an dieser Stelle zwei Optionen:

1. Häufigkeitstabelle erstellen und ablesen.
2. Ein package benutzen, dass eine Funktion für den Modus hat.

Eine Häufigkeitstabelle bekommen wir sehr einfach mit `table`:

```{r freq_table}
table(qmsurvey$zufrieden)
```

Das ist zwar optisch wenig beeindruckend, aber wir können immerhin einfach erkennen, dass der Wert `4` die größte absolute Höufigkeit hat. Passt.

Alternativ können wir die `tadaatoolbox` benutzen:

```{r modus_toolbox}
library(tadaatoolbox)

modus(qmsurvey$zufrieden)
```

Vollkommen unerwartet kommen wir zum gleichen Ergebnis.  
Who'da thunk.  
Für die EnthusiastInnen:  
Die `modus`-Funktion macht übrigens auch nichts anderes als eine Häufigkeitstabelle via `table`, aus der dann das Maximum extrahiert wird.  
Praktisch nur `names(table(x)[table(x) == max(table(x))])` mit ein bisschen Glitzer und so.

Wenn wir das jetzt noch in schön und übersichtlich haben wollen, können wir auf `sjPlot` zurückgreifen:

```{r freq_sjt, warning=FALSE, message=FALSE}
library(sjPlot)

sjt.frq(qmsurvey$zufrieden, emph.md = TRUE, emph.quart = TRUE)
```

Da fällt eine Tabelle raus, die uns Median, die Häufigkeiten, fehlende Werte und in der Fußzeile gleich auch gesamt-N, Mittelwert und Standardabweichung anzeigt.  
Über `emph.quart = TRUE` sagen wir auch, dass die Quartile eingezeichnet werden sollen, was in diesem Beispiel etwas versagt.  
Eine bessere Demonstration:

```{r freq_sjt_2}
sjt.frq(qmsurvey$alter, emph.md = TRUE, emph.quart = TRUE)
```

Hier haben wir zwei rote Linien für das 25%- und 75%-Quartile und fett/rote Schrift für den Median.  
Voll schön.

### Variabilität

Hier ist die Situation ähnlich wie im vorigen Abschnitt: Varianz und Standardabweichung sind geschenkt, Variation ist seltsam.

```{r var_sd}
var(qmsurvey$zufrieden)
sd(qmsurvey$zufrieden)
```

Wenig überraschend. Solange ihr euch merken könnt, dass *Standardabweichung* auf englisch ***s**tandard **d**eviation* heißt, sollte das kein Problem sein.  
Die Variation hingegen wird so selten als Maß benutzt, dass es dafür keine dedizierte Funktion gibt – analog der Modus-Sache von weiter oben. Da das allerdings _wirklich_ kein Mensch braucht, bleibt euch nichts anderes übrig als die Varianz zu berechnen und mit $n-1$ zu multiplizieren.  

¯\\\_(ツ)_/¯

Okay, ihr könnt natürlich auch *ganz cool* sein und euch eine **eigene Funktion** schreiben! Wie die großen!

So etwa:

```{r variation}
variation <- function(x) {
  # NA rauskicken
  x <- x[!is.na(x)]
  # Variation berechnen
  variation <- sum((x - mean(x))^2)
  # Und zurückgeben
  return(variation)
}
```

Das war... Definitiv etwas, das wir gerade getan haben!  

```{r variation_2}
variation(qmsurvey$zufrieden)
```

Funktioniert.  
Braucht nur wie gesagt kein Mensch, aber jetzt habt ihr immerhin mal so grob gesehen, wie Funktionen schreiben in R funktioniert.  
'Tis not witchcraft.  
Aber okay, ich schweife ab.

### Variabilität auf Ordinalskala

Auf Ordinalskala haben wir den Mittelwert nicht zur Verfügung. Das macht uns alle sehr traurig.  
Aus diesem Grund müssen wir auf den Median ausweichen, den wir dann noch dezent mit Quantilen garnieren können.  
Wenn wir nochmal die Variable `Zufriedenheit` aus `qmsurvey` nehmen:

```{r median}
median(qmsurvey$zufrieden)
```

Wenig beeindruckend.  
Für Quantile:

```{r quantiles}
quantile(qmsurvey$zufrieden)
```

Wir können auch beliebige andere Quantile berechnen, die `quantile`-Funktion gibt uns nur per default Quartile, weil die am gängigsten sind:

```{r quantiles_2}
quantile(qmsurvey$alter, probs = c(.333, .666))
```

Über `probs` geben wir der Funktion einen *Vektor aus Wahrscheinlichkeiten* für die entsprechenden Quantile. Hier haben wir also das 33%- und das 66%-Quantil berechnet.  
Um beispielsweise Dezile zu erhalten brauchen wir also einen Vektor der Wahrscheinlichkeiten von 0 bis 10 in 10% oder 0.1er Schritten, den wir einfach via `seq` erstellen können:

```{r quantiles_3}
quantile(qmsurvey$alter, probs = seq(from = 0, to = 1, by = 0.1))
```

Ein weiteres gängiges Maß für die Variabilität ist die **Spannweite**, die auf Ordinalskala und aufwärts sinnvoll sein kann.  
Gemeint ist damit nichts anderes als der Abstand vom kleinsten zum größten Wert, also nichts besonders komplexes. In R können wir da die `min` und `max`-Funktionen für die beiden Werte benutzen, oder `range` für beide zusammen:

```{r range}
min(qmsurvey$alter)
max(qmsurvey$alter)
range(qmsurvey$alter)

max(qmsurvey$alter) - min(qmsurvey$alter)
```

Die Altersspanne in QM (und damit so grob im Psychologiestudiengang) ist also 19 Jahre.  
Bahnbrechende Erkenntnisse die wir hier einfach so raushauen.

## Bivariate Statistiken

### Nominalskala

Auf Nominalskala ist $\chi^2$ unser bester Freund. Leider ist es auch ein etwas übelriechender, buckliger Freund, den wir nur selten zu uns nach Hause einladen – zumindest in Deskriptivstatistikland.

Als Beispiel nehemn wir mal *Geschlecht* und *Cannabiskonsum*:

```{r nomstats_1}
library(sjPlot)

sjt.xtab(qmsurvey$cannabis, qmsurvey$gender,
         show.exp = TRUE, show.legend = TRUE)
```

Die Berechnung in R ist einfach:

```{r nomstats_2}
chisq.test(qmsurvey$cannabis, qmsurvey$gender)
# Reihenfolge egal
chisq.test(qmsurvey$gender, qmsurvey$cannabis)
```

Das Output ist nicht so hübsch und etwas clunky und beinhaltet auch p-Wert und Freiheitsgrade, die euch eigentlich nur in einem inferenzstatistischen Kontext interessieren.  
Darüber hinaus kann es sein, dass der berechnete Wert nicht mit händischer Berechnung übereinstimmt.  
Der Grund dafür ist [Yates' Kontinuitätskorrektor](https://en.wikipedia.org/wiki/Chi-squared_test#Yates.27s_correction_for_continuity), die nur bei 2x2-Tabellen greift. Solltet ihr die Korrektur explizit deaktivieren wollen, könnt ihr das Argument `correct = FALSE` setzen.

Für kompakteres Output haben wir eine entsprechende Funktion in der *tadaatoolbox*:

```{r nomstats_3, message=FALSE}
library(tadaatoolbox)

nom_chisqu(qmsurvey$gender, qmsurvey$cannabis)
```

Als nächstes haben wir die auf $\chi^2$-basierenden Statistiken **Phi** ($\phi$) und **Cramer's V**, die entsprechenden Funktionen kommen auch aus der *tadaatoolbox*:

```{r nomstats_4}
nom_phi(qmsurvey$gender, qmsurvey$cannabis)
nom_v(qmsurvey$gender, qmsurvey$cannabis)
```

Oh nein, Phi funktioniert nicht. Wie unerwartet.  
Ihr mögt euch erinnern, dass Phi nur für 2x2-Tabellen definiert ist, wobei Cramer's V bei beliebigen Tabellendimensionen funktioniert – darüberhinaus sind die beiden Statistiken im Falle von 2x2-Tabellen auch noch identisch, weshalb sich die Frage aufwirft, wieso überhaupt jemand Phi benutzen sollte – aber nun gut, die Funktionen sind da.

Als letztes gibt es noch den **Kontingenzkoeffizient C** – keine Ahnung was der für eine Daseinsberechtigung hat, aber wenn ihr ihn mal braucht:

```{r nomstats_5}
nom_c(qmsurvey$gender, qmsurvey$cannabis)
```

Sagte ich *als letztes*? Das war gelogen. Es gibt noch **Lambda** ($\lambda$) in drei Geschmacksrichtungen:

1. "Sorum" (Variablen wie definiert)
2. "Andersrum" (x- und y-Variable vertauschen)
3. Symmetrisch

```{r nomstats_6}
nom_lambda(qmsurvey$gender, qmsurvey$cannabis)
nom_lambda(qmsurvey$gender, qmsurvey$cannabis, reverse = TRUE)
nom_lambda(qmsurvey$gender, qmsurvey$cannabis, symmetric = TRUE)
```

Es gibt zusätzlich die Funktion `assocstats` aus dem `vcd`-Package. Da gebt ihr allerdings nicht beide Variablen einzeln an, sondern einen `table` der beiden Variablen:

```{r nomstats_7}
library(vcd)

freq_table <- table(qmsurvey$gender, qmsurvey$cannabis)
freq_table

assocstats(freq_table)
```
So könnt ihr die gängigen Statistiken auf einen Blick sehen.  
Alternativ haben wir dafür natürlich auch was in der *tadaatoolbox*:

```{r nomstats_8}
tadaa_nom(qmsurvey$gender, qmsurvey$cannabis, print = "markdown")
```

Das Argument `print = "markdown"` ist nur für das Output in diesem Buch bzw. in RMarkdown-Dokumenten relevant, für die Nutzung in der Konsole könnt ihr das weglassen.  
Aber ihr benutzt ja jetzt eh alle brav RMarkdown, seit ihr das entsprechende Kapitel dazu hier überflogen habt, ja?  
Ja.  
Brav.

### Ordinalskala

Auf Ordinalskala haben wir primär **Gamma**, **Somers' d** und eine Handvoll **Tau** abzufrühstücken.  
Um's einach zu halten bedienen wir uns auch hier wieder der *tadaatoolbox*:

```{r ordstats_1}
ord_gamma(qmsurvey$lernen, qmsurvey$zufrieden)

ord_somers_d(qmsurvey$lernen, qmsurvey$zufrieden)
ord_somers_d(qmsurvey$lernen, qmsurvey$zufrieden, reverse = TRUE)
ord_somers_d(qmsurvey$lernen, qmsurvey$zufrieden, symmetric = TRUE)
```

Wobei **Somers' d'** analog Lambda drei Geschmacksrichtungen hat.  

Oder auch hier, alle zusammen:

```{r ordstats_2}
tadaa_ord(qmsurvey$lernen, qmsurvey$zufrieden, print = "markdown")
```

Da sind dann auch gleich die Taus mit drin. Die könnt ihr auch einzeln bekommen:

```{r ordstats_3}
ord_tau(qmsurvey$lernen, qmsurvey$zufrieden, tau = "a")
ord_tau(qmsurvey$lernen, qmsurvey$zufrieden, tau = "b")
ord_tau(qmsurvey$lernen, qmsurvey$zufrieden, tau = "c")
```

Da $\tau_b$ auch als Korrelationskoeffizient durchgeht, gibts's den auch via `cor`:

```{r ordstats_4}
cor(qmsurvey$lernen, qmsurvey$zufrieden, method = "kendall")
```

### Intervallskala

Hier fangen die spaßigen Dinge an. Korrelationen und so.  
Und was ist Korrelation?  
Die standardisierte Kovarianz, nämlich.  
Und was ist Kovarianz?

```{r intstats}
cov(qmsurvey$alter, qmsurvey$beziehungen, use = "complete.obs")
```

Nämlich.  
`cov` gibt uns die **Kovarianz**, wenig überraschend, und über `use = "complete.obs"` spezifizieren wir, dass Beobachtungspaare mit fehlenden Werten (`NA`) ausgelassen werden sollen. Eine Alternative wäre `"pairwise.complete.obs"`, was in diesem Fall keinen Unterschied macht, aber prinzipiell wollt ihr eins von beidem benutzen um zu verhindern, dass ihr als Ergebnis nur ein trauriges `NA` bekommt.

Als nächstes also die Korrelationskoeffizienten:

- **Pearson's** $r$
- **Spearman's** $\rho$

Beide bekommen wir mit `cor`, abhängig vom `method`-Argument. Der Default ist `"pearson"`

```{r intstats_3}
cor(qmsurvey$alter, qmsurvey$beziehungen, use = "complete.obs")
cor(qmsurvey$alter, qmsurvey$beziehungen, use = "complete.obs", method = "spearman")
```

Über `method = "kendall"` bekommen wir auch Kendall's $\tau_b$. Just in case.

### Regression <small>Teil 1</small>

Regression ist ein _riesiges_ Thema, und der Umstand, dass ich ein 600-seitiges Buch dazu habe, sollte euch ein grobes Gefühl dafür geben, _wie_ umfangreich es sein kann.  
In QM1 schauen wir uns die Regression nur in einem relativ simplen Kontext an: Lineare Regression.  
Weiterhin interessieren wir uns (vorerst) noch nicht für p-Werte, t-Statistiken und Signifikanz, und auch Modellgütekriterien sind erstmal uninteressant.  
Wir benutzen Regression hier erstmal ausschließlich zur Evaluation linearer Zusammenhänge. 
Also los:

Mal angenommen, wir wollen wissen ob bei *Game of Thrones* im Laufe der Serie mehr gestorben wird, sprich wir wollen wissen, ob es einen positiven Zusammenhang zwischen der *Staffel* und der *Anzahl der Tode pro Staffel* gibt. Dafür müssen wir unseren `gotdeaths`-Datensatz etwas umtransformieren:

```{r ch11_regression_1, message=FALSE, warning=FALSE}
library(dplyr)

gotdeaths_perseason <- gotdeaths %>%
  group_by(death_season) %>%
  summarize(deaths = n())

knitr::kable(gotdeaths_perseason)
```

Jetzt haben wir zwei simple Variablen: Die Staffel und die Anzahl der Tode pro Staffel. Damit lässt sich arbeiten. Vorher wollen wir uns das aber erstmal kurz anschauen:

```{r ch11_regression_plot}
library(ggplot2)

ggplot(data = gotdeaths_perseason, aes(x = death_season, y = deaths)) +
  geom_point(size = 3) +
  geom_smooth(method = lm, se = FALSE, color = "red") +
  scale_x_continuous(breaks = 1:6) +
  labs(title = "Game of Thrones", subtitle = "Deaths per Season",
       x = "Season", y = "Deaths")
```

In diesem einfachen Scatterplot haben wir auch gleich eine *Regressionsgerade* via `geom_smooth(method = lm)`,
das ist die gleiche Gerade, die durch unsere Regressionkoeffizienten definiert wird.  
Und wo kommen die her?  
Aus `lm` – der Funktion, mit der wir *lineare Modelle* erstellen:

```{r ch11_regression_2}
model <- lm(deaths ~ death_season, data = gotdeaths_perseason)
```

In den meisten Quellen zum Thema werdet ihr vermutlich jetzt darauf gestoßen, das Output von `lm` in `summary` zu stecken, was zwar die relevanten Ergebnisse liefert, dabei aber leider unschön aussieht:

```{r ch11_regression_3}
summary(model)
```

Eine kompaktere Variante finden wie im package `broom`:

```{r ch11_regression_4}
library(broom)

tidy(model) %>%
  knitr::kable(digits = 3) # kable wieder nur für die Optik im Buch
```

Hier ist `tidy` dazu da, die Koeffizienten als einfachen `data.frame` auszuspucken, das sich besser zur Darstellung in einer Tabelle eignet. Hier fehlt uns jetzt aber beispielsweise das $R^2$, aber natürlich gibt's auch da was:

```{r ch11_regression_5}
sjt.lm(model)
```

Generell würde ich `sjPlot` bzw. `sjt.lm` zur Darstellung von Regressionsmodellen empfehlen: Die Funktion ist von Haus aus auf hübsches Output ausgelegt, und ist ausreichend modifizierbar um das Output so spartanisch oder umfassend wie gewänscht aussehen zu lassen.

### Weitere Statistiken

- Kendall's W
- Inter-Rater-Reliability-Kram via `irr`
