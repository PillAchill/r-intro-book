---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Statistische Tests

## Tests auf Voraussetzungen

### Tests auf Normalvertielung

Wenn es um Teststärke geht hat der **Shapiro-Wilk**-Test die Nase vorn, der sollte also so der Standardtest sein, den ihr erstmal probiert. R hat den auch von Haus aus dabei:

```{r shapiro}
shapiro.test(qmsurvey$partnerinnen)
```

Solltet ihr mal andere Tests brauchen, hat das package `nortest` noch einige andere gängige:

```{r normtests, warning=FALSE}
library(nortest)

# Anderson-Darling (ganz gut)
ad.test(qmsurvey$partnerinnen)
# Shapiro-Francia (auch ganz gut)
sf.test(qmsurvey$partnerinnen)
# Lilliefors (okay)
lillie.test(qmsurvey$partnerinnen)
# Pearson's Chi^2-Anpassungstest (meh)
pearson.test(qmsurvey$partnerinnen)
# Kolmogorov-Smirnoff (einfach nicht benutzen)
ks.test(scale(qmsurvey$partnerinnen), y = pnorm)
```


### Tests auf Varianzhomogenität

Der gängigste Test auf *Varianzhomogenität* (oder auch *Homoskedasizität* bzw. analog *Heteroskedastizität* für *Varianzheterogenität*) ist der **Levene Test**, den wir aus dem `car` package holen:

```{r levene_1}
library(car)

leveneTest(partnerinnen ~ ons, data = qmsurvey)
```

Hier haben wir auf *Varianzheterogenität* getestet in den Gruppen, die durch `ons` (`"Hattest du schon einmal einen One-Night-Stand?"`) entstehen (`Ja` und `Nein`), mit dem abhängigen Merkmal `partnerinnen` (`"Wie viele Sexualpartner*innen hast du bisher gehabt?"`).  
Beachtet die Tilde (`~`) in der Funktion. Das ist eine von diesen *formulas*, die in R-Modelldefinitionen gerne auftauchen. Erstmal nicht weiter beachten, nur merken: Links steht die abhängige (intervallskalierte) Variable, und rechts steht die *Gruppierungsvariable*, in der Regel nominalskaliert.

```{r leven_2}
library(tadaatoolbox)

tadaa_levene(qmsurvey, partnerinnen ~ ons, print = "markdown")
```


## $\chi^2$

Zu einem sauberen $\chi^2$-Test gehört auch immer eine saubere Kontingenztabelle, und da greifen wir wie gehabt auf `sjPlot` zurück:

```{r chisq_xtab}
library(sjPlot)

sjt.xtab(qmsurvey$ons, qmsurvey$ernaehrung,
         show.exp = TRUE, show.legend = TRUE, show.cell.prc = TRUE)
```

Den $\chi^2$-Test finden wir dann in *base R*, no packages required:

```{r chisq_base_r}
chisq.test(qmsurvey$ons, qmsurvey$ernaehrung)
```

Wenn ihr dasselbe Ergebnis nur in ein bisschen aufgeräumt und mit bonus-Cramer's-V als Effektgröße haben wollt, haben wir da was in der toolbox:

```{r chisq_test}
library(tadaatoolbox)

tadaa_chisq(qmsurvey, ons, ernaehrung, print = "markdown")
```

## z- und t-Test

### Eine Stichprobe

```{r z-Test}
tadaa_one_sample(qmsurvey, x = alter, mu = 20, sigma = 3, print = "markdown")
```

```{r t-test_onesample}
tadaa_one_sample(qmsurvey, x = alter, mu = 20, print = "markdown")
```

### Zwei Stichproben

R bringt die t-Test-Funktion von Haus aus mit, die ist zwar nicht besonders schön, aber sie macht alles wichtige:

```{r t-test_twosample}
t.test(partnerinnen ~ ons, data = qmsurvey)
```

Wichtige Argumente:
- `var.equal`: Varianzen gleich? `TRUE`/`FALSE`, für Varianzhomogenität
    - Im Zweifelsfall lieber auf `FALSE` (default) lassen, sicherheitshalber.
- `paired`: Wenn `TRUE` wird ein *abhängiger* t-Test gemacht, bei `FALSE` (default) ein *unabhängiger*.

Alternativ haben wir da was in der toolbox:

```{r t-test_twosample_tadaa}
tadaa_t.test(qmsurvey, response = partnerinnen, group = ons, paired = FALSE, print = "markdown")
```

Die Funktion macht im Vergleich zu `t.test()` noch folgendes:
- Automatische Varianzhomogenitätserkennung via eingebautem Levene-Test
- Automatische Effektgrößenberechnung (*Cohen's d*)
- Automatische Teststärkenberechnung via `pwr`-package (Spalte `Power`)

## Varianzanalyse (ANOVA)

### Einfaktorielle ANOVA

### Mehrfaktorielle ANOVA

### ANOVA mit Messwiederholung (rmANOVA)

## Regression

### Einfache Lineare Regression

### Multiple Regression

### Logistische Regression
